# Mode switch (local now, openai later)
LLM_MODE=local

# Ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=phi3:mini

# Storage
CHROMA_DIR=./data/chroma
UPLOAD_DIR=./data/uploads

# RAG defaults
TOP_K=4
CHUNK_SIZE=900
CHUNK_OVERLAP=150
